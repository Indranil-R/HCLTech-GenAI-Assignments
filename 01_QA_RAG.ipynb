{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Indranil-R/Silver-Badge-Assignments/blob/main/1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copilot Documentation - Question Answering RAG\n",
        "\n",
        "This project is a part of silver certification\n",
        "- Implement a question answering system with RAG, word embedding, vector database, langchain, llm and any other tools"
      ],
      "metadata": {
        "id": "legOMZKl-G-H"
      },
      "id": "legOMZKl-G-H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Project Setup"
      ],
      "metadata": {
        "id": "vaQ0i97y-x3i"
      },
      "id": "vaQ0i97y-x3i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "Z___5hbj-2fL"
      },
      "id": "Z___5hbj-2fL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing libraries\n",
        "!pip install -q google google-genai langchain loguru pypdf langchain-community langchain-chroma langchain-google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaAk4bYh_y6-",
        "outputId": "8345cb72-00ae-4e0f-8e55-52c179d25e06"
      },
      "id": "GaAk4bYh_y6-",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from loguru import logger\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "u_WgMgGo_b2W"
      },
      "id": "u_WgMgGo_b2W",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Variables"
      ],
      "metadata": {
        "id": "vB1OAuRN_o1p"
      },
      "id": "vB1OAuRN_o1p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Google API key\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "if os.environ[\"GOOGLE_API_KEY\"] != None:\n",
        "  logger.info(\"Google API key loaded\")\n",
        "else:\n",
        "  logger.error(\"Google API key not loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxTQbSJ4_rCy",
        "outputId": "b63f0d67-8113-4a79-d03b-a19445c9d009"
      },
      "id": "sxTQbSJ4_rCy",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 02:11:10.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mGoogle API key loaded\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Ingestion"
      ],
      "metadata": {
        "id": "TCS9XGEW-9Gg"
      },
      "id": "TCS9XGEW-9Gg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIryV7yQ-zrp",
        "outputId": "0703cf0d-bfff-47c0-93a9-055169eaba2d"
      },
      "id": "VIryV7yQ-zrp",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the PDF file\n",
        "file_path = \"/content/drive/MyDrive/Colab Documents/copilot.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(file_path,mode=\"page\")\n",
        "pages = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "logger.info(f\"Number of documents: {len(docs)}\\n\")\n",
        "logger.info(\"Data ingestion step is completed.. Moving on to embedding\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCCiOObUFMf9",
        "outputId": "8f82b5c3-d791-40e4-d7d3-c747ae1733f3"
      },
      "id": "yCCiOObUFMf9",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 02:58:42.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mNumber of documents: 56\n",
            "\u001b[0m\n",
            "\u001b[32m2025-05-17 02:58:42.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mData ingestion step is completed.. Moving on to embedding\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Embedding Generation"
      ],
      "metadata": {
        "id": "Hv-YAz3N-_0l"
      },
      "id": "Hv-YAz3N-_0l"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_fn = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "persist_directory = '/content/drive/MyDrive/Colab Documents/db'\n",
        "\n",
        "if not os.path.exists(persist_directory):\n",
        "    logger.info(f'Creating a new directory at {persist_directory}')\n",
        "    os.makedirs(persist_directory, exist_ok=True)\n",
        "\n",
        "# Creating the memory vector database\n",
        "vectordb = Chroma.from_documents(documents=docs,embedding=embedding_fn,persist_directory=persist_directory)\n",
        "\n",
        "logger.info(\"Embedding generation step is completed.. Moving on to retriever\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Cvqauf_BUk",
        "outputId": "abd85af0-a9f7-47a5-c106-0840654c24f2"
      },
      "id": "52Cvqauf_BUk",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 02:59:16.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mCreating a new directory at /content/drive/MyDrive/Colab Documents/db\u001b[0m\n",
            "\u001b[32m2025-05-17 02:59:20.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mEmbedding generation step is completed.. Moving on to retriever\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Retriever Setup"
      ],
      "metadata": {
        "id": "ru_o6fFm_ECH"
      },
      "id": "ru_o6fFm_ECH"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 7})\n",
        "logger.info(\"Retriever setup is completed.. Moving on to RAG chain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6GTbBkY_Fdq",
        "outputId": "80ffd232-3138-45d5-d33f-4699acf2b468"
      },
      "id": "t6GTbBkY_Fdq",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 03:01:44.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mRetriever setup is completed.. Moving on to RAG chain\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. RAG Chain Construction"
      ],
      "metadata": {
        "id": "-Gv1yGKf_H1W"
      },
      "id": "-Gv1yGKf_H1W"
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",temperature=0.1, max_tokens=5000)\n",
        "logger.info(f\"Initialized {llm.model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L-MAHB3_JhM",
        "outputId": "99b40a6e-c3a2-4c4c-daca-9721c7801e3a"
      },
      "id": "_L-MAHB3_JhM",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 03:29:10.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mInitialized models/gemini-2.0-flash\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer the question.\"\n",
        "    \"If you don't know the answer, say that you don't know.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        "   )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "CwQl4zv7Mk_a"
      },
      "id": "CwQl4zv7Mk_a",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "kLzzlN8xPRNE"
      },
      "id": "kLzzlN8xPRNE",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the LLM RAG Model"
      ],
      "metadata": {
        "id": "ZlJJXoZAQvRV"
      },
      "id": "ZlJJXoZAQvRV"
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"How to Enable Copilot Chat in Edge\"})\n",
        "display(Markdown(response[\"answer\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "GYqIVBW0Oyql",
        "outputId": "58307895-bba3-493e-c6ce-c3acf3ca07f2"
      },
      "id": "GYqIVBW0Oyql",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To use Copilot Chat in Edge, follow these steps:\n\n1.  Sign in to Microsoft Edge with your Microsoft Entra account (work or school account).\n2.  Access Copilot Chat by clicking the Copilot icon in the upper right of the Edge browser (Ctrl+Shift+.).\n\nA shield icon at the top of the Copilot Chat experience in the sidebar confirms that Copilot Chat in Edge offers enterprise data protection."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"What features are available in Copilot Chat?\"})\n",
        "display(Markdown(response[\"answer\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "rblK0qQWPcTR",
        "outputId": "9ef95f7d-56b6-4a67-813e-64f2be4cfe40"
      },
      "id": "rblK0qQWPcTR",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Copilot Chat has many features, including:\n*   Copilot Pages: Takes Copilot Chat-generated content and puts it in a dynamic, persistent canvas where users can edit it, add to it, share it, and work on it with others in real time.\n*   File upload: Lets users upload files like Word docs, Excel files, and PDFs to prompt Copilot Chat to reason over it as part of its response.\n*   Image generation: Create an AI-generated image by describing it.\n*   Previous chats: Lets users access previous chats for reference or to continue the chat.\n*   Agents: Agents use AI to automate and execute business processes, working alongside or on behalf of a person, team, or organization.\n*   Contextual prompt suggestions (Copilot Chat in Edge): References open pages within Microsoft Edge to help users create more relevant prompts.\n*   Page summarization (Copilot Chat in Edge): Lets users summarize an open webpage or PDF in Edge.\n*   Code interpreter: Copilot Chat uses the Python programming language to help users perform complex data analysis such as coding, visualization, and math.\n*   Image upload: Lets users take photos, upload images, or copy and paste images into Copilot Chat to use in a prompt."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"How to Enable agents?\"})\n",
        "display(Markdown(response[\"answer\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "yovZU27eP8bL",
        "outputId": "a1e2e465-1f96-4100-9532-585419941b27"
      },
      "id": "yovZU27eP8bL",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To enable agents that are billed based on metered consumption for users in Copilot Chat, admins need to set up or use an existing Copilot Studio subscription. Admins can set up billing through either the Microsoft 365 admin center (MAC) or the Power Platform admin center (PPAC)."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"Can you tell me about ESOP?\"})\n",
        "display(Markdown(response[\"answer\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "lV0NoAqCQ7qZ",
        "outputId": "427196f2-f7f5-4eb7-f2e9-7afee3bc07f4"
      },
      "id": "lV0NoAqCQ7qZ",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I'm sorry, but the provided context does not contain information about ESOP (Employee Stock Ownership Plan). Therefore, I cannot answer your question."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qs9jFwi_SlMx"
      },
      "id": "Qs9jFwi_SlMx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}